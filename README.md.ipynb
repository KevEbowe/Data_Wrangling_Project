{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wrangle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project i performed data wrangling on files sourced from the twitter archives of user \"weRateDogs\". WeRateDogs is a twitter account that contain data on different dog breeds. The data was gathered through different methods;\n",
    "1.tweet image file was downloaded using the request library, to download and open the file containing the required data from WeRateDogs archive.\n",
    "2.twitter_archive file was already provided as a \".csv\" file, so the it was read into a pandas dataframe for assessment\n",
    "3.twitter's api was needed for the last set of data. An aunthetication key which consisted;consumer_key,consumer_secret,access_token and access_secret, was required to access twitter's api and the python library \"tweepy\" was used to query twitter api for the required data. This queried data was read as a json.txt file and subsequently appended into a list and saved as a \".csv\" file.\n",
    "\n",
    "After gathering the required data, they were all read into different pandas dataframes. Visual and programmatic assessments were made on the different dataframes to check for data quality and tidiness issues. some of these issues were:\n",
    "-incorrect datatypes\n",
    "-misrepresented values in some columns\n",
    "-irrelevant columns in the dataset (e.g only original data were required, retweet data were not needed)\n",
    "\n",
    "When these isssues were found and highlighted, the data proceeded to the next phase, which is the cleaning phase. This is where all the highlighted data quality and tidiness issues were cleaned. This is a crucial stage in the data wrangling process as cleaning the data ensures the datasets are free from errors, allows for accurate analysis and ensures data is not skewed wrongly.\n",
    "\n",
    "Upon cleaning the data, the cleaned data was saved into a new csv file, ready to move to the the analysis and visualization stage where insights can be gotten based on the data in the file and also insights are all visualized for better understanding of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
